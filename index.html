<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Slides Projet NLP1</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-markdown>
			  <textarea data-template>
				# Projet NLP1
				#### Reconnaissance de commandes dâ€™assistant domotique


				##### https://github.com/Eldolfin/projet-NLP1

				##### https://github.com/Eldolfin/slides-NLP1

				Groupe 7 SCIA, Promo 2026
				- Alexis.petignat
				- Baptiste.villeneuve
				- Oscar.le-dauphin
				- Lucas.juanico
				- Max.nagaishi


				Note:
				Alexis qui parle ğŸ—£ï¸ğŸ—£ï¸ğŸ”¥
				

				---

				![](https://media1.tenor.com/m/gWXA2gvEmrQAAAAC/alexa-amazon.gif)

				---

				# Sommaire
				- ğŸ—ƒï¸ Le dataset
				- âœ¨ Les modÃ¨les
				- ğŸ“ˆ Benchmaks
				- â• Les extras

				Note:
				Alexis qui parle ğŸ—£ï¸ğŸ—£ï¸ğŸ”¥

				---

				## Le dataset
				![](assets/massive.png)
				---

				## Le dataset

				- **Source** : MASSIVE
				- **Focus** : Sous-ensemble `fr-FR` (~16.5k Ã©noncÃ©s)
				- *Train: 11.5k, Validation: 2k, Test: 3k*
				- **Objectif** : Reconnaissance de commandes d'assistant domotique
				- **Structure** :
				    - 18 ScÃ©narios
				    - 60 Intents
				- **Approche** : PrÃ©diction ScÃ©nario â” PrÃ©diction Intent

				Note:
				basptiste qui parle ğŸ—£ï¸ğŸ—£ï¸ğŸ”¥
				magnifique ce dataset
				---

				| Type | Distribution |
				|------|--------------|
				| Scenarios | ![](assets/scenario_distribution.png) |
				| Intent | ![](assets/intent_distribution.png) |

				---

				## Dataset : Analyse `fr-FR`

				- **Forces :**
				  - **Pertinent** & Annotations de qualitÃ©
				  - **Taille** `fr-FR` importante et catÃ©gories claires

				- **Faiblesses & DÃ©fis :**
				  - **Gros dÃ©sÃ©quilibre des classes**
				- Biais potentiels
				- Absence de contexte conversationnel

				---

				## Bag of words
				![](assets/bagofwords_image.png)
				```python
				sklearn.feature_extraction.text.CountVectorizer
				```
				- RÃ©gression Logistique
				- Training: < 1s


				---

				## Bag of words
				![](./assets/BAGOFWORDS_report.png)


				---

				## N-grams				
				![](assets/ngrams_image.png)

				---

				## N-grams
				- ImplÃ©mentation Maison
				- N = 2, 3, 4 (custom)
				- GÃ©nÃ©ration de texte
				- Training: 1-10s

				
				---

				### N-grams
				![](./assets/NGRAMS_report.png)
				---

				### TF-IDF
				![](./assets/tfidf_image.png)

				---

				### TF-IDF
				```python
				sklearn.feature_extraction.text.TfidfVectorizer
				```
				- RÃ©gression Logistique
				- Training: < 3s



				---

				### TF-IDF
				![](./assets/IDF_report.png)


				---

				### Word2Vec
				![](assets/word2vec_image.png)

				---

				### Word2Vec
				```python
				SentenceTransformer("dangvantuan/sentence-camembert-large")
				```
				- RÃ©gression Logistique
				- Training: ~10mn

				---
				### Feedforward
				![](assets/fnn_image.png)

				Notes: 
				Lucas qui parle ğŸ—£ï¸ğŸ—£ï¸ğŸ”¥
				- 3 modÃ¨les et des hyperparamÃ¨tres diffÃ©rents
				- 3 embeddings diffÃ©rents: tf-idf et 2 modÃ¨les prÃ©entrainÃ©s w2v
				- pr w2v, on a fait la moyenne de chaque embedding de mot
				---
				### Feedforward


				| ModÃ¨le          | Hidden Size | Learning Rate | Train Loss | Test Loss | Accuracy |
				|----------------|-------------|---------------|------------|-----------|----------|
				| tf-idf         | 100         | 1e-4          | 0.091      | 0.40      | 0.89 |
				| w2v (google)   | 1000        | 0.001         |1.62        | 1.53      | 0.54  |
				| w2v (fasttext) | 1000        | 0.001         | 0.37       | 1.26      | 0.74  |

				Notes: 
				- prÃ©senter tableau
				- le modÃ¨le w2v de google = modÃ¨le prÃ©entrainÃ© sur le dataset Google-news
				- w2v fastext en est un autre entrainÃ© sur des donnÃ©es en franÃ§ais
				- 100 Ã©poques d'entrainement
				- solution retenue = tf-idf

				---
				
				### RNN
				![](assets/rnn_image.png)

				Notes:
				- 4 modÃ¨les et hyperparams
				- embeddings onehot, w2v entrainÃ© sur nos donnÃ©es et les 2 w2v prÃ©entrainÃ©s

				---
				### RNN


				| Model        | Learning Rate | Epochs | Test Loss | Accuracy |
				|--------------|---------------|--------|-----------|-----------|
				| onehot       | 0.01          | 30     | 0.80      | 0.84   |
				| w2v          | 0.1           | 30     | 1.66      | 0.55    |
				| w2v (google)   | 0.01          | 100    | 0.85      | 0.77     |
				| w2v (fasttext) | 0.01          | 200    | 0.90      | 0.79    |

				Notes: 
				-prÃ©senter tableau
				-Le nombre de couches de RNN et la bidirectionalitÃ© nÃ©gligeable dans nos tests
				- solution retenue = w2v
				
				---
				### Transformers
				![](assets/transformers_image.png)
				---
				### Transformers
				```python
				from transformers import Trainer
				```
				- Training: 1h+
				---
				## Benchmarks
				| Method           | Training time | F1 score (scenario)  | F1 score (intent) |
				|------------------|---------------|----------------------|-------------------|
				| BoW              | 1s            | 0.81                 | 0.784             |
				| N-grams          | 10s           | 0.69                 | 0.65              |
				| TF-IDF           | 3s            | 0.85                 | 0.845             |
				| Word2Vec         | 10m           | 0.894                | 0.876             |
				| FNN              | 30m           | 0.89                 | ?                 |
				| RNN              | 30m           | 0.84                 | ?                 |
				| Transformers     | +1h           | 0.911                | ?                 |
				---

				### Speach to text
				- **Technologie** : **Whisper** d'OpenAI (modÃ¨le `small`).
				- *Pourquoi Whisper?* Haute performance, robuste (accents, bruits de fond), intÃ©gration Python facile, diffÃ©rentes tailles de modÃ¨le.
				- **ImplÃ©mentation** :
					1. Capture Audio
					2. PrÃ©-traitement Audio
					3. Transcription
				- **Limitations** :
				    - FiabilitÃ©.
					- Latence/Vitesse.

				---

				## App terminal

				- TUI: Text-based User Interface 
				- [Textualize](https://textual.textualize.io/)
				- Demo time ğŸ”¥

				Note:
				- Au debut: simple input() python
				- Update Ã  chaque touche
				- Animations, des progress bars, etc
				- On peut changer le theme ğŸ˜
				- Il y une autocompletion, basÃ©e sur gÃ©nÃ©ration NGRAMS
				---
				<video controls width="1920">
				  <source src="assets/demo.mp4" type="video/mp4">
				  Your browser does not support the video tag.
				</video>

				Note:
				- Au debut: simple input() python
				- Update Ã  chaque touche
				- Animations, des progress bars, etc
				- On peut changer le theme ğŸ˜
				- Il y une autocompletion, basÃ©e sur gÃ©nÃ©ration NGRAMS
				---

				# Questions ?
				![](https://media1.tenor.com/m/y1HuEzMn_b8AAAAC/cute-emoji.gif) 
			</textarea>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			controls: false,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes],

			markdown: {
				smartypants: true
			}
		});
	</script>
</body>

</html>
